{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please  construct  a  new  dataset  by  either  adding  two  independent  variables  or  removing  two independent\n",
    "#variables  from  finalsample.dta  dataset.  If  you  choose  to  add  two  independent variables, you could add\n",
    "#any two independent variables that you think help explain stock returns. If  you  choose  to  remove  two  \n",
    "#independent  variables,  you  could  remove  any  two  independent variables that already exist in the \n",
    "#finalsample.dta dataset.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import statsmodels.api as sm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "plt.rcParams['figure.figsize'] = [20, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gvkey', 'datadate', 'sic_2', 'lagdate', 'lagRet2', 'lagVOL2',\n",
       "       'lagPrice2', 'lagMV2', 'lagShareturnover2', 'lagRet2_sic', 'lagRet12',\n",
       "       'lagVOL12', 'lagShareturnover12', 'lagRet12_std', 'lagRet12_min',\n",
       "       'lagRet12_max', 'lagRet12_sic', 'lagdatadate', 'atq', 'ceqq', 'cheq',\n",
       "       'dlttq', 'epspiq', 'saleq', 'dvpspq', 'sp500_ret_d', 'nasdaq_ret_d',\n",
       "       'r2000_ret_d', 'dollar_ret_d', 'VIX', 'yield_3m', 'yield_10y',\n",
       "       'gdp_growth', 'Bull_ave', 'Bull_Bear', 'ret', 'debt', 'cash', 'sale',\n",
       "       'BM', 'PE', 'div_p', 'loglagPrice2', 'loglagVOL12', 'loglagMV2',\n",
       "       'logatq', 'loglagVOL2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndata=pd.read_stata('/Users/jimmyaspras/Downloads/finalsample.dta')\n",
    "nndata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-e895412330a8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nndata1['Year']=nndata1['datadate'].dt.year\n",
      "<ipython-input-3-e895412330a8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nndata1['Month']=nndata1['datadate'].dt.month\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sic_2</th>\n",
       "      <th>lagdate</th>\n",
       "      <th>lagRet2</th>\n",
       "      <th>lagVOL2</th>\n",
       "      <th>lagPrice2</th>\n",
       "      <th>lagMV2</th>\n",
       "      <th>lagShareturnover2</th>\n",
       "      <th>lagRet2_sic</th>\n",
       "      <th>lagRet12</th>\n",
       "      <th>lagVOL12</th>\n",
       "      <th>...</th>\n",
       "      <th>BM</th>\n",
       "      <th>PE</th>\n",
       "      <th>div_p</th>\n",
       "      <th>loglagPrice2</th>\n",
       "      <th>loglagVOL12</th>\n",
       "      <th>loglagMV2</th>\n",
       "      <th>logatq</th>\n",
       "      <th>loglagVOL2</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvkey</th>\n",
       "      <th>datadate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004.0</th>\n",
       "      <th>2001-04-30</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>-0.104674</td>\n",
       "      <td>1129800.0</td>\n",
       "      <td>13.600</td>\n",
       "      <td>366.27520</td>\n",
       "      <td>0.041950</td>\n",
       "      <td>-0.048423</td>\n",
       "      <td>0.052613</td>\n",
       "      <td>1481250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931715</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>2.610070</td>\n",
       "      <td>14.208397</td>\n",
       "      <td>5.903385</td>\n",
       "      <td>6.650203</td>\n",
       "      <td>13.937551</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30915.0</th>\n",
       "      <th>2001-04-30</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>-0.050095</td>\n",
       "      <td>63300.0</td>\n",
       "      <td>10.050</td>\n",
       "      <td>91.80675</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>-0.018221</td>\n",
       "      <td>239500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.624488</td>\n",
       "      <td>37.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.307573</td>\n",
       "      <td>12.386309</td>\n",
       "      <td>4.519686</td>\n",
       "      <td>5.489338</td>\n",
       "      <td>11.055641</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31170.0</th>\n",
       "      <th>2001-04-30</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>-0.079365</td>\n",
       "      <td>296200.0</td>\n",
       "      <td>7.250</td>\n",
       "      <td>44.02925</td>\n",
       "      <td>0.048773</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>-0.005784</td>\n",
       "      <td>345900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076057</td>\n",
       "      <td>34.523810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>12.753905</td>\n",
       "      <td>3.784854</td>\n",
       "      <td>4.315018</td>\n",
       "      <td>12.598790</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31600.0</th>\n",
       "      <th>2001-04-30</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>-0.035294</td>\n",
       "      <td>1058400.0</td>\n",
       "      <td>5.125</td>\n",
       "      <td>84.70600</td>\n",
       "      <td>0.064037</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>1158450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.812655</td>\n",
       "      <td>36.607143</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>1.634131</td>\n",
       "      <td>13.962593</td>\n",
       "      <td>4.439186</td>\n",
       "      <td>6.527946</td>\n",
       "      <td>13.872269</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61635.0</th>\n",
       "      <th>2001-04-30</th>\n",
       "      <td>33.0</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>201200.0</td>\n",
       "      <td>11.750</td>\n",
       "      <td>76.35150</td>\n",
       "      <td>0.030963</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.318682</td>\n",
       "      <td>341450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.379685</td>\n",
       "      <td>28.658537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.463853</td>\n",
       "      <td>12.740957</td>\n",
       "      <td>4.335348</td>\n",
       "      <td>5.667520</td>\n",
       "      <td>12.212055</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sic_2    lagdate   lagRet2    lagVOL2  lagPrice2  \\\n",
       "gvkey   datadate                                                       \n",
       "1004.0  2001-04-30   50.0 2001-02-28 -0.104674  1129800.0     13.600   \n",
       "30915.0 2001-04-30   33.0 2001-02-28 -0.050095    63300.0     10.050   \n",
       "31170.0 2001-04-30   33.0 2001-02-28 -0.079365   296200.0      7.250   \n",
       "31600.0 2001-04-30   33.0 2001-02-28 -0.035294  1058400.0      5.125   \n",
       "61635.0 2001-04-30   33.0 2001-02-28  0.044444   201200.0     11.750   \n",
       "\n",
       "                       lagMV2  lagShareturnover2  lagRet2_sic  lagRet12  \\\n",
       "gvkey   datadate                                                          \n",
       "1004.0  2001-04-30  366.27520           0.041950    -0.048423  0.052613   \n",
       "30915.0 2001-04-30   91.80675           0.006929     0.004113 -0.018221   \n",
       "31170.0 2001-04-30   44.02925           0.048773     0.004113 -0.005784   \n",
       "31600.0 2001-04-30   84.70600           0.064037     0.004113  0.078186   \n",
       "61635.0 2001-04-30   76.35150           0.030963     0.004113  0.318682   \n",
       "\n",
       "                     lagVOL12  ...        BM         PE     div_p  \\\n",
       "gvkey   datadate               ...                                  \n",
       "1004.0  2001-04-30  1481250.0  ...  0.931715  85.000000  0.006250   \n",
       "30915.0 2001-04-30   239500.0  ...  1.624488  37.222222  0.000000   \n",
       "31170.0 2001-04-30   345900.0  ...  1.076057  34.523810  0.000000   \n",
       "31600.0 2001-04-30  1158450.0  ...  3.812655  36.607143  0.009756   \n",
       "61635.0 2001-04-30   341450.0  ...  1.379685  28.658537  0.000000   \n",
       "\n",
       "                    loglagPrice2  loglagVOL12 loglagMV2    logatq  loglagVOL2  \\\n",
       "gvkey   datadate                                                                \n",
       "1004.0  2001-04-30      2.610070    14.208397  5.903385  6.650203   13.937551   \n",
       "30915.0 2001-04-30      2.307573    12.386309  4.519686  5.489338   11.055641   \n",
       "31170.0 2001-04-30      1.981001    12.753905  3.784854  4.315018   12.598790   \n",
       "31600.0 2001-04-30      1.634131    13.962593  4.439186  6.527946   13.872269   \n",
       "61635.0 2001-04-30      2.463853    12.740957  4.335348  5.667520   12.212055   \n",
       "\n",
       "                    Year  Month  \n",
       "gvkey   datadate                 \n",
       "1004.0  2001-04-30  2001      4  \n",
       "30915.0 2001-04-30  2001      4  \n",
       "31170.0 2001-04-30  2001      4  \n",
       "31600.0 2001-04-30  2001      4  \n",
       "61635.0 2001-04-30  2001      4  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndata.sort_values(by=['datadate'], inplace=True)\n",
    "nndata1=nndata[nndata['lagPrice2']>=5]#remove penny stocks\n",
    "nndata1['Year']=nndata1['datadate'].dt.year\n",
    "nndata1['Month']=nndata1['datadate'].dt.month\n",
    "#set gvkey and datadate as the index\n",
    "nndata1=nndata1.set_index(['gvkey','datadate'])\n",
    "nndata1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split  your  new  dataset  into  training  and  testing  samples.  Testing  sample  should  include  data with\n",
    "#year>=2016. \n",
    "#\n",
    "#Drop dvpspq and atq from the train/test data\n",
    "#\n",
    "train=nndata1[nndata1['Year']<2016]\n",
    "X_train=train[['sic_2', 'lagRet2', 'lagVOL2',\n",
    "       'lagPrice2', 'lagMV2', 'lagShareturnover2', 'lagRet2_sic', 'lagRet12',\n",
    "       'lagVOL12', 'lagShareturnover12', 'lagRet12_std', 'lagRet12_min',\n",
    "       'lagRet12_max', 'lagRet12_sic', 'ceqq', 'cheq',\n",
    "       'dlttq', 'epspiq', 'saleq', 'sp500_ret_d', 'nasdaq_ret_d',\n",
    "       'r2000_ret_d', 'dollar_ret_d', 'VIX', 'yield_3m', 'yield_10y',\n",
    "       'gdp_growth', 'Bull_ave', 'Bull_Bear', 'ret', 'debt', 'cash', 'sale',\n",
    "       'BM', 'PE', 'div_p', 'loglagPrice2', 'loglagVOL12', 'loglagMV2',\n",
    "       'logatq', 'loglagVOL2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set return as the dependent training variable\n",
    "Y_train=train[['ret']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set testing independent variables\n",
    "test=nndata1[nndata1['Year']>=2016]\n",
    "X_test=test[['sic_2', 'lagRet2', 'lagVOL2',\n",
    "       'lagPrice2', 'lagMV2', 'lagShareturnover2', 'lagRet2_sic', 'lagRet12',\n",
    "       'lagVOL12', 'lagShareturnover12', 'lagRet12_std', 'lagRet12_min',\n",
    "       'lagRet12_max', 'lagRet12_sic', 'ceqq', 'cheq',\n",
    "       'dlttq', 'epspiq', 'saleq', 'sp500_ret_d', 'nasdaq_ret_d',\n",
    "       'r2000_ret_d', 'dollar_ret_d', 'VIX', 'yield_3m', 'yield_10y',\n",
    "       'gdp_growth', 'Bull_ave', 'Bull_Bear', 'ret', 'debt', 'cash', 'sale',\n",
    "       'BM', 'PE', 'div_p', 'loglagPrice2', 'loglagVOL12', 'loglagMV2',\n",
    "       'logatq', 'loglagVOL2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set return as the dependent testing variable\n",
    "Y_test=test[['ret']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate avg monthly risk free return\n",
    "rf1=pd.read_excel(\"/Users/jimmyaspras/Downloads/Treasury bill.xlsx\")\n",
    "rf1['rf']=rf1['DGS3MO']/1200\n",
    "rf2=rf1[['Date','rf']].dropna()\n",
    "rf2['Year']=rf2['Date'].dt.year\n",
    "rf2['Month']=rf2['Date'].dt.month\n",
    "rf3=rf2[['Year','Month','rf']].groupby(['Year','Month'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import benchmark index return\n",
    "indexret1=pd.read_stata(\"/Users/jimmyaspras/Downloads/Index return.dta\")\n",
    "#Import factors data\n",
    "Factor=pd.read_excel(\"/Users/jimmyaspras/Downloads/Factors.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build  a  neural  network  with  one  hidden  layer  and  20  neurons  in  the  hidden  layer.  Set  batch \n",
    "#size=10,000.  Use  GridSearchCV  to  search  for  the  best  value  of  epochs  among  [10,  20,  30,  40]. Use  \n",
    "#the  best value  of  epochs  found  in  the  search  to  train  this  neural  network  using  your  new training \n",
    "#sample. Use the trained neural network to predict returns based on your new testing sample. Report the average \n",
    "#return of the portfolio that consists of the 100 stocks with the highest predicted returns in each year-month. \n",
    "#Also, report the Sharpe ratio of the portfolio. \n",
    "def shallownetwork():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(20,kernel_initializer='uniform',activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='Adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([10.97182283,  8.14502058, 12.20729866, 16.87534151]),\n",
       " 'std_fit_time': array([2.02224683, 1.5556716 , 1.79913007, 4.94902274]),\n",
       " 'mean_score_time': array([3.55519547, 4.03498945, 4.05364237, 3.30667205]),\n",
       " 'std_score_time': array([1.14943611, 0.70416456, 1.47834758, 2.14423576]),\n",
       " 'param_epochs': masked_array(data=[10, 20, 30, 40],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'epochs': 10}, {'epochs': 20}, {'epochs': 30}, {'epochs': 40}],\n",
       " 'split0_test_score': array([-3.15814442e+09, -1.45939508e+09, -8.41260678e+08, -1.47120575e+07]),\n",
       " 'split1_test_score': array([-1.42508775e+10, -5.88534408e+08, -8.67318107e+07, -7.57039395e+09]),\n",
       " 'split2_test_score': array([-6.71055384e+09, -2.37823606e+09, -2.70078202e+08, -2.63812739e+07]),\n",
       " 'split3_test_score': array([-2.39900563e+08, -2.68398658e+08, -4.05095026e+06, -2.62379774e+07]),\n",
       " 'split4_test_score': array([-1.70744964e+08, -1.21994167e+08, -8.90234850e+06, -8.62186709e+07]),\n",
       " 'mean_test_score': array([-4.90604425e+09, -9.63311674e+08, -2.42204798e+08, -1.54478879e+09]),\n",
       " 'std_test_score': array([5.25039566e+09, 8.46083566e+08, 3.14631217e+08, 3.01290680e+09]),\n",
       " 'rank_test_score': array([4, 2, 1, 3], dtype=int32)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsplit=TimeSeriesSplit(n_splits=5,test_size=50000,gap=5000)\n",
    "model1=KerasRegressor(build_fn=shallownetwork)\n",
    "param_candidate={'epochs': [10,20,30,40]}\n",
    "grid=GridSearchCV(estimator=model1,param_grid=param_candidate,n_jobs=-1,cv=tsplit,scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train,Y_train,batch_size=10000,verbose=0)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 30}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "56/56 [==============================] - 1s 8ms/step - loss: 2066401853440.0000\n",
      "Epoch 2/30\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 23360057344.0000\n",
      "Epoch 3/30\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 7124564992.0000\n",
      "Epoch 4/30\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 5289424896.0000\n",
      "Epoch 5/30\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 3722147584.0000\n",
      "Epoch 6/30\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 2614666752.0000\n",
      "Epoch 7/30\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1806205312.0000\n",
      "Epoch 8/30\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1949585792.0000\n",
      "Epoch 9/30\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1245196928.0000\n",
      "Epoch 10/30\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 849846848.0000\n",
      "Epoch 11/30\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 687818432.0000\n",
      "Epoch 12/30\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 634526592.0000\n",
      "Epoch 13/30\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 523601024.0000\n",
      "Epoch 14/30\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 443556704.0000\n",
      "Epoch 15/30\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 420633248.0000\n",
      "Epoch 16/30\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 391242496.0000\n",
      "Epoch 17/30\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 397232416.0000\n",
      "Epoch 18/30\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 370197664.0000A: 0s - loss: 542853\n",
      "Epoch 19/30\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 370088096.0000\n",
      "Epoch 20/30\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 337419168.0000\n",
      "Epoch 21/30\n",
      "56/56 [==============================] - 1s 21ms/step - loss: 316344032.0000\n",
      "Epoch 22/30\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 306606880.0000\n",
      "Epoch 23/30\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 265712336.0000\n",
      "Epoch 24/30\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 269047232.0000\n",
      "Epoch 25/30\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 263306384.0000A: 0s - loss: 251923936\n",
      "Epoch 26/30\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 262815184.0000\n",
      "Epoch 27/30\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 257568176.0000\n",
      "Epoch 28/30\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 248022288.0000\n",
      "Epoch 29/30\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 239025312.0000\n",
      "Epoch 30/30\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 276061184.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89284bccd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnretrain=shallownetwork()\n",
    "#**grid.best_params_ feeds epochs directly into the model fitting\n",
    "nnretrain.fit(X_train,Y_train,**grid.best_params_,batch_size=10000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict=pd.DataFrame(nnretrain.predict(X_test),columns=['Y_predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test1=pd.DataFrame(Y_test).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>ret</td>       <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 12 Aug 2021</td> <th>  Prob (F-statistic):</th>  <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:01:25</td>     <th>  Log-Likelihood:    </th> <td>  85.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    64</td>      <th>  AIC:               </th> <td>  -169.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    63</td>      <th>  BIC:               </th> <td>  -167.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     0</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC0</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0149</td> <td>    0.008</td> <td>    1.876</td> <td> 0.065</td> <td>   -0.001</td> <td>    0.031</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.400</td> <th>  Durbin-Watson:     </th> <td>   2.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  47.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.580</td> <th>  Prob(JB):          </th> <td>4.06e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.074</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors are heteroscedasticity robust (HC0)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    ret   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                  0.000\n",
       "Method:                 Least Squares   F-statistic:                       nan\n",
       "Date:                Thu, 12 Aug 2021   Prob (F-statistic):                nan\n",
       "Time:                        21:01:25   Log-Likelihood:                 85.629\n",
       "No. Observations:                  64   AIC:                            -169.3\n",
       "Df Residuals:                      63   BIC:                            -167.1\n",
       "Df Model:                           0                                         \n",
       "Covariance Type:                  HC0                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0149      0.008      1.876      0.065      -0.001       0.031\n",
       "==============================================================================\n",
       "Omnibus:                       16.400   Durbin-Watson:                   2.169\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               47.856\n",
       "Skew:                          -0.580   Prob(JB):                     4.06e-11\n",
       "Kurtosis:                       7.074   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC0)\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comb1=pd.merge(Y_test1, Y_predict, left_index=True,right_index=True,how='inner')\n",
    "Comb1['Year']=Comb1['datadate'].dt.year\n",
    "Comb1['Month']=Comb1['datadate'].dt.month\n",
    "rank1=Comb1[['Y_predict','Year', 'Month']].groupby(['Year','Month'],as_index=False).rank(ascending=False)\n",
    "rank1.rename(columns={'Y_predict':'Y_predict_rank'},inplace=True)\n",
    "stock_long1=pd.merge(Comb1,rank1,left_index=True, right_index=True)\n",
    "stock_long2=stock_long1[stock_long1['Y_predict_rank']<=100]\n",
    "stock_long2['datadate'].value_counts()\n",
    "stock_long3=stock_long2[['ret','Year','Month']].groupby(['Year','Month']).mean()\n",
    "stock_long4=pd.merge(stock_long3, rf3, left_on=['Year','Month'], right_on=['Year','Month'], how='left')\n",
    "stock_long5=pd.merge(stock_long4, indexret1, left_on=['Year','Month'], right_on=['Year','Month'], how='left')\n",
    "stock_long5['ret_rf']=stock_long5['ret']-stock_long5['rf']\n",
    "stock_long5['ret_sp500']=stock_long5['ret']-stock_long5['sp500_ret_m']\n",
    "stock_long5=sm.add_constant(stock_long5)\n",
    "sm.OLS(stock_long5[['ret']],stock_long5[['const']]).fit().get_robustcov_results(cov_type='HC0').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return of 1.49% over market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ret_rf    0.755798\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ret_rf=stock_long5[['ret_rf']]\n",
    "SR=(Ret_rf.mean()/Ret_rf.std())*np.sqrt(12)\n",
    "SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a deep neural network with more than 2 hidden layers. Feel free to pick the number of hidden layers. Use \n",
    "#RandomizedSearchCV to search for the best values of epochs, batch size, and the  number  of  neurons  in  each  \n",
    "#hidden  layer.  Use  the  best  values  of  epochs,  batch  size,  and  the number of neurons in each hidden layer\n",
    "#found in the search to train the deep neural network using your new training sample. Use the trained deep neural \n",
    "#network to predict returns based on your new testing sample. Report the average return of the portfolio that \n",
    "#consists of the 100 stocks with the highest predicted returns in each year-month. Also, report the Sharpe ratio \n",
    "#of the portfolio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnetwork(no_neuron1,no_neuron2,no_neuron3,no_neuron4,no_neuron5,no_neuron6,no_neuron7,no_neuron8,no_neuron9,no_neuron10):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(no_neuron1, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron2, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron3, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron4, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron5, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron6, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron7, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron9, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(no_neuron10, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnetworktsplit=TimeSeriesSplit(n_splits=5, test_size=50000, gap=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'no_neuron1': randint(10,100),\n",
    "              'no_neuron2': randint(10,100),\n",
    "              'no_neuron3': randint(10,100),\n",
    "              'no_neuron4': randint(10,100),\n",
    "              'no_neuron5': randint(10,100),\n",
    "              'no_neuron6': randint(10,100),\n",
    "              'no_neuron7': randint(10,100),\n",
    "              'no_neuron8': randint(10,100),\n",
    "              'no_neuron9': randint(10,100),\n",
    "              'no_neuron10': randint(10,100),\n",
    "              'epochs': randint(10,50),\n",
    "              'batch_size': randint(10000,50000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([166.63865571, 180.74396281,  90.85305777, 157.7881814 ,\n",
       "         97.5726676 ]),\n",
       " 'std_fit_time': array([24.30869409, 31.50696439, 17.61875564, 28.10562476,  5.55643238]),\n",
       " 'mean_score_time': array([1.85407853, 2.13774819, 1.82200356, 1.93170042, 1.2208168 ]),\n",
       " 'std_score_time': array([0.23885812, 0.18154211, 0.27361068, 0.4278632 , 0.59177206]),\n",
       " 'param_batch_size': masked_array(data=[38088, 33355, 15925, 13336, 11593],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[32, 47, 13, 38, 33],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron1': masked_array(data=[10, 21, 73, 40, 43],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron10': masked_array(data=[31, 11, 26, 20, 92],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron2': masked_array(data=[19, 17, 42, 67, 20],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron3': masked_array(data=[62, 16, 22, 40, 55],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron4': masked_array(data=[34, 39, 86, 79, 27],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron5': masked_array(data=[69, 66, 59, 86, 27],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron6': masked_array(data=[98, 30, 69, 16, 33],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron7': masked_array(data=[82, 69, 80, 72, 53],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron8': masked_array(data=[14, 62, 83, 25, 42],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_no_neuron9': masked_array(data=[82, 73, 91, 59, 35],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'batch_size': 38088,\n",
       "   'epochs': 32,\n",
       "   'no_neuron1': 10,\n",
       "   'no_neuron10': 31,\n",
       "   'no_neuron2': 19,\n",
       "   'no_neuron3': 62,\n",
       "   'no_neuron4': 34,\n",
       "   'no_neuron5': 69,\n",
       "   'no_neuron6': 98,\n",
       "   'no_neuron7': 82,\n",
       "   'no_neuron8': 14,\n",
       "   'no_neuron9': 82},\n",
       "  {'batch_size': 33355,\n",
       "   'epochs': 47,\n",
       "   'no_neuron1': 21,\n",
       "   'no_neuron10': 11,\n",
       "   'no_neuron2': 17,\n",
       "   'no_neuron3': 16,\n",
       "   'no_neuron4': 39,\n",
       "   'no_neuron5': 66,\n",
       "   'no_neuron6': 30,\n",
       "   'no_neuron7': 69,\n",
       "   'no_neuron8': 62,\n",
       "   'no_neuron9': 73},\n",
       "  {'batch_size': 15925,\n",
       "   'epochs': 13,\n",
       "   'no_neuron1': 73,\n",
       "   'no_neuron10': 26,\n",
       "   'no_neuron2': 42,\n",
       "   'no_neuron3': 22,\n",
       "   'no_neuron4': 86,\n",
       "   'no_neuron5': 59,\n",
       "   'no_neuron6': 69,\n",
       "   'no_neuron7': 80,\n",
       "   'no_neuron8': 83,\n",
       "   'no_neuron9': 91},\n",
       "  {'batch_size': 13336,\n",
       "   'epochs': 38,\n",
       "   'no_neuron1': 40,\n",
       "   'no_neuron10': 20,\n",
       "   'no_neuron2': 67,\n",
       "   'no_neuron3': 40,\n",
       "   'no_neuron4': 79,\n",
       "   'no_neuron5': 86,\n",
       "   'no_neuron6': 16,\n",
       "   'no_neuron7': 72,\n",
       "   'no_neuron8': 25,\n",
       "   'no_neuron9': 59},\n",
       "  {'batch_size': 11593,\n",
       "   'epochs': 33,\n",
       "   'no_neuron1': 43,\n",
       "   'no_neuron10': 92,\n",
       "   'no_neuron2': 20,\n",
       "   'no_neuron3': 55,\n",
       "   'no_neuron4': 27,\n",
       "   'no_neuron5': 27,\n",
       "   'no_neuron6': 33,\n",
       "   'no_neuron7': 53,\n",
       "   'no_neuron8': 42,\n",
       "   'no_neuron9': 35}],\n",
       " 'split0_test_score': array([-0.02356919, -0.02356026, -0.02355748, -0.02361717, -0.02354337]),\n",
       " 'split1_test_score': array([-0.0139035 , -0.01393325, -0.01390268, -0.01390728, -0.01391561]),\n",
       " 'split2_test_score': array([-0.00955511, -0.00949796, -0.00953448, -0.00950806, -0.00955835]),\n",
       " 'split3_test_score': array([-0.01029308, -0.01031498, -0.01032081, -0.01029169, -0.01030374]),\n",
       " 'split4_test_score': array([-0.01350855, -0.01355092, -0.01353668, -0.01357631, -0.01352828]),\n",
       " 'mean_test_score': array([-0.01416589, -0.01417147, -0.01417043, -0.0141801 , -0.01416987]),\n",
       " 'std_test_score': array([0.00500362, 0.0050061 , 0.00499803, 0.00502882, 0.00499103]),\n",
       " 'rank_test_score': array([1, 4, 3, 5, 2], dtype=int32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = KerasRegressor(build_fn=deepnetwork)\n",
    "rgrid = RandomizedSearchCV(estimator=model2, param_distributions=param_dist, n_iter=5, cv=deepnetworktsplit,\n",
    "                           scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rgrid.fit(X_train,Y_train,verbose=0)\n",
    "rgrid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 38088,\n",
       " 'epochs': 32,\n",
       " 'no_neuron1': 10,\n",
       " 'no_neuron10': 31,\n",
       " 'no_neuron2': 19,\n",
       " 'no_neuron3': 62,\n",
       " 'no_neuron4': 34,\n",
       " 'no_neuron5': 69,\n",
       " 'no_neuron6': 98,\n",
       " 'no_neuron7': 82,\n",
       " 'no_neuron8': 14,\n",
       " 'no_neuron9': 82}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rgrid.best_params_['no_neuronX'] feeds neuron output from best params into model\n",
    "def deepnetwork1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron1'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron2'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron3'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron4'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron5'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron6'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron7'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron8'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron9'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(rgrid.best_params_['no_neuron10'], kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer='Adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "15/15 [==============================] - 4s 182ms/step - loss: 0.0195\n",
      "Epoch 2/32\n",
      "15/15 [==============================] - 3s 166ms/step - loss: 0.0191\n",
      "Epoch 3/32\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 0.0191\n",
      "Epoch 4/32\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 0.0191\n",
      "Epoch 5/32\n",
      "15/15 [==============================] - 4s 241ms/step - loss: 0.0191\n",
      "Epoch 6/32\n",
      "15/15 [==============================] - 3s 204ms/step - loss: 0.0191\n",
      "Epoch 7/32\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 0.0191\n",
      "Epoch 8/32\n",
      "15/15 [==============================] - 3s 178ms/step - loss: 0.0191\n",
      "Epoch 9/32\n",
      "15/15 [==============================] - 4s 247ms/step - loss: 0.0191\n",
      "Epoch 10/32\n",
      "15/15 [==============================] - 4s 299ms/step - loss: 0.0191\n",
      "Epoch 11/32\n",
      "15/15 [==============================] - 4s 258ms/step - loss: 0.0191\n",
      "Epoch 12/32\n",
      "15/15 [==============================] - 3s 181ms/step - loss: 0.0191\n",
      "Epoch 13/32\n",
      "15/15 [==============================] - 3s 201ms/step - loss: 0.0191\n",
      "Epoch 14/32\n",
      "15/15 [==============================] - 3s 193ms/step - loss: 0.0191\n",
      "Epoch 15/32\n",
      "15/15 [==============================] - 3s 196ms/step - loss: 0.0191\n",
      "Epoch 16/32\n",
      "15/15 [==============================] - 3s 192ms/step - loss: 0.0191\n",
      "Epoch 17/32\n",
      "15/15 [==============================] - 3s 185ms/step - loss: 0.0191\n",
      "Epoch 18/32\n",
      "15/15 [==============================] - 3s 199ms/step - loss: 0.0191\n",
      "Epoch 19/32\n",
      "15/15 [==============================] - 3s 178ms/step - loss: 0.0191\n",
      "Epoch 20/32\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 0.0191\n",
      "Epoch 21/32\n",
      "15/15 [==============================] - 3s 176ms/step - loss: 0.0191\n",
      "Epoch 22/32\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 0.0191\n",
      "Epoch 23/32\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 0.0191\n",
      "Epoch 24/32\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 0.0191\n",
      "Epoch 25/32\n",
      "15/15 [==============================] - 3s 179ms/step - loss: 0.0191\n",
      "Epoch 26/32\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 0.0191\n",
      "Epoch 27/32\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 0.0191\n",
      "Epoch 28/32\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 0.0191\n",
      "Epoch 29/32\n",
      "15/15 [==============================] - 3s 180ms/step - loss: 0.0191\n",
      "Epoch 30/32\n",
      "15/15 [==============================] - 3s 218ms/step - loss: 0.0191\n",
      "Epoch 31/32\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 0.0191\n",
      "Epoch 32/32\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 0.0191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8928026040>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_n=deepnetwork1()\n",
    "#best params fed directky into model fit\n",
    "deep_n.fit(X_train,Y_train,epochs=rgrid.best_params_['epochs'],batch_size=rgrid.best_params_['batch_size'],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict2=pd.DataFrame(deep_n.predict(X_test),columns=['Y_predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test2=pd.DataFrame(Y_test).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>ret</td>       <th>  R-squared:         </th> <td>  -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 12 Aug 2021</td> <th>  Prob (F-statistic):</th>  <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:19:44</td>     <th>  Log-Likelihood:    </th> <td>  116.31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    64</td>      <th>  AIC:               </th> <td>  -230.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    63</td>      <th>  BIC:               </th> <td>  -228.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     0</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC0</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0111</td> <td>    0.005</td> <td>    2.258</td> <td> 0.027</td> <td>    0.001</td> <td>    0.021</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>67.101</td> <th>  Durbin-Watson:     </th> <td>   1.659</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 718.538</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.758</td> <th>  Prob(JB):          </th> <td>9.36e-157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.461</td> <th>  Cond. No.          </th> <td>    1.00</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors are heteroscedasticity robust (HC0)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    ret   R-squared:                      -0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                       nan\n",
       "Date:                Thu, 12 Aug 2021   Prob (F-statistic):                nan\n",
       "Time:                        21:19:44   Log-Likelihood:                 116.31\n",
       "No. Observations:                  64   AIC:                            -230.6\n",
       "Df Residuals:                      63   BIC:                            -228.5\n",
       "Df Model:                           0                                         \n",
       "Covariance Type:                  HC0                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0111      0.005      2.258      0.027       0.001       0.021\n",
       "==============================================================================\n",
       "Omnibus:                       67.101   Durbin-Watson:                   1.659\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              718.538\n",
       "Skew:                          -2.758   Prob(JB):                    9.36e-157\n",
       "Kurtosis:                      18.461   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC0)\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comb1=pd.merge(Y_test2, Y_predict2, left_index=True,right_index=True,how='inner')\n",
    "Comb1['Year']=Comb1['datadate'].dt.year\n",
    "Comb1['Month']=Comb1['datadate'].dt.month\n",
    "rank1=Comb1[['Y_predict','Year', 'Month']].groupby(['Year','Month'],as_index=False).rank(ascending=False)\n",
    "rank1.rename(columns={'Y_predict':'Y_predict_rank'},inplace=True)\n",
    "stock_long1=pd.merge(Comb1,rank1,left_index=True, right_index=True)\n",
    "stock_long2=stock_long1[stock_long1['Y_predict_rank']<=100]\n",
    "stock_long2['datadate'].value_counts()\n",
    "stock_long3=stock_long2[['ret','Year','Month']].groupby(['Year','Month']).mean()\n",
    "stock_long4=pd.merge(stock_long3, rf3, left_on=['Year','Month'], right_on=['Year','Month'], how='left')\n",
    "stock_long5=pd.merge(stock_long4, indexret1, left_on=['Year','Month'], right_on=['Year','Month'], how='left')\n",
    "stock_long5['ret_rf']=stock_long5['ret']-stock_long5['rf']\n",
    "stock_long5['ret_sp500']=stock_long5['ret']-stock_long5['sp500_ret_m']\n",
    "stock_long5=sm.add_constant(stock_long5)\n",
    "sm.OLS(stock_long5[['ret']],stock_long5[['const']]).fit().get_robustcov_results(cov_type='HC0').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1% over market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ret_rf    0.88788\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ret_rfdeepnetwork=stock_long5[['ret_rf']]\n",
    "SRdeepnetwork=(Ret_rfdeepnetwork.mean()/Ret_rfdeepnetwork.std())*np.sqrt(12)\n",
    "SRdeepnetwork"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
